{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center\">CrossEntropyLoss</h3> \n",
    "<h4 style=\"text-align: center\">relation with NLLLoss and LogSoftmax</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature:\n",
      "torch.Size([5, 3])\n",
      "tensor([[-0.9997,  0.9024,  1.5058],\n",
      "        [ 1.2295, -1.2791,  0.6434],\n",
      "        [-1.9006,  1.4064,  1.3669],\n",
      "        [-0.8453,  0.9917,  0.6591],\n",
      "        [ 0.3560,  0.9731,  0.3480]])\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_classes = 5, 3\n",
    "x = torch.randn(batch_size, n_classes)\n",
    "print(\"feature:\")\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:\n",
      "tensor([2, 0, 0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(n_classes, size=(batch_size,), dtype=torch.long)\n",
    "print(\"target:\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax2(x): return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "def softmax(x):  return x.exp() / (x.exp().sum(-1)).unsqueeze(-1)\n",
    "def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "def nl(input, target): return -input[range(target.shape[0]), target].log().mean()\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above expressions are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9932, -1.0911, -0.4877],\n",
      "        [-0.4934, -3.0020, -1.0795],\n",
      "        [-3.9991, -0.6921, -0.7316],\n",
      "        [-2.4664, -0.6293, -0.9619],\n",
      "        [-1.3469, -0.7298, -1.3550]])\n",
      "tensor([[-2.9932, -1.0911, -0.4877],\n",
      "        [-0.4934, -3.0020, -1.0795],\n",
      "        [-3.9991, -0.6921, -0.7316],\n",
      "        [-2.4664, -0.6293, -0.9619],\n",
      "        [-1.3469, -0.7298, -1.3550]])\n",
      "tensor([[-2.9932, -1.0911, -0.4877],\n",
      "        [-0.4934, -3.0020, -1.0795],\n",
      "        [-3.9991, -0.6921, -0.7316],\n",
      "        [-2.4664, -0.6293, -0.9619],\n",
      "        [-1.3469, -0.7298, -1.3550]])\n",
      "tensor([[-2.9932, -1.0911, -0.4877],\n",
      "        [-0.4934, -3.0020, -1.0795],\n",
      "        [-3.9991, -0.6921, -0.7316],\n",
      "        [-2.4664, -0.6293, -0.9619],\n",
      "        [-1.3469, -0.7298, -1.3550]])\n"
     ]
    }
   ],
   "source": [
    "print( log_softmax(x) )\n",
    "print( nn.LogSoftmax(dim=1)(x) )\n",
    "print( torch.log(softmax(x)))\n",
    "print( torch.log(nn.Softmax(dim=1)(x)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>CrossEntropyLoss = NLLLoss(LogSoftmax(x),target)</p>\n",
    "<p>This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7603)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss()(nn.LogSoftmax(dim=1)(x), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7603)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(log_softmax(x),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7603)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()(x,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7603)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()(nn.LogSoftmax(dim=1)(x),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(1.7603)\n",
      "2 tensor(1.7603)\n",
      "3 tensor(1.7603)\n",
      "4 tensor(1.7603)\n"
     ]
    }
   ],
   "source": [
    "print(\"1\",nn.CrossEntropyLoss()(x,target))\n",
    "print(\"2\",nn.NLLLoss()(nn.LogSoftmax(dim=1)(x),target))\n",
    "print(\"3\",nn.CrossEntropyLoss()(nn.LogSoftmax(dim=1)(x),target))\n",
    "print(\"4\",nn.NLLLoss()( nn.LogSoftmax(dim=1)(nn.LogSoftmax(dim=1)(x)) ,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7603)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(log_softmax(x),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7603)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(log_softmax(log_softmax(x)),target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLLLoss \"mechanism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9024, 0.6434, 1.3669, 0.6591, 0.3560])\n"
     ]
    }
   ],
   "source": [
    "target = torch.LongTensor([1, 2, 2, 2, 0])\n",
    "print(  x[range(target.shape[0]), target]   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "#matrix diagonal selection\n",
    "y = torch.Tensor([[0,1,1,1,1],\n",
    "                  [1,0,1,1,1],\n",
    "                  [1,1,0,1,1],\n",
    "                  [1,1,1,0,1],\n",
    "                  [1,1,1,1,0]])\n",
    "\n",
    "ax0 = [0,1,2,3,4]\n",
    "ax1 = [0,1,2,3,4]\n",
    "\n",
    "print(y[ax0,ax1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reference:</p>\n",
    "<a href=\"https://medium.com/@zhang_yang/understanding-cross-entropy-implementation-in-pytorch-softmax-log-softmax-nll-cross-entropy-416a2b200e34\">How is Pytorchâ€™s Cross Entropy function related to softmax, log softmax, and NLL</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
