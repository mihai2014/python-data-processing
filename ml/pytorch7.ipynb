{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center\">MNIST dataset training (I)</h3>\n",
    "<h4 style=\"text-align: center\">fully-connected network - pytorch</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #if color\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Compose creates a series of transformation to prepare the dataset.</p> \n",
    "<p>Torchvision reads datasets into PILImage (Python imaging format).</p> \n",
    "<p>ToTensor converts the PIL Image from range [0, 255] to a FloatTensor of shape (C x H x W) with range [0.0, 1.0].</p> \n",
    "<p>We then renormalize the input to [-1, 1] based on the following formula with Î¼=standard deviation=0.5.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "#print(type(images))\n",
    "#print(images.shape)\n",
    "#print(labels.shape)\n",
    "#%matplotlib inline\n",
    "#print(\"labels\",labels)\n",
    "#plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = nn.Sequential(nn.Linear(784, 128),\n",
    "#                      nn.ReLU(),\n",
    "#                      nn.Linear(128, 64),\n",
    "#                      nn.ReLU(),\n",
    "#                      nn.Linear(64, 10),\n",
    "#                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# Use GPU if it's available\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(\"using:\",device)\n",
    "\n",
    "#for device in ['cpu', 'cuda']:\n",
    "\n",
    "#    start = time.time()\n",
    "    \n",
    "#    model.to(device)\n",
    "    \n",
    "#    epochs = 3\n",
    "#    for e in range(epochs):\n",
    "#        print(\"epoch\",e)\n",
    "#        running_loss = 0\n",
    "#        for images, labels in trainloader:\n",
    "            #images = images.to(device)\n",
    "            #labels = labels.to(device)\n",
    "#            images, labels = images.to(device), labels.to(device)        \n",
    "            \n",
    "            # Flatten MNIST images into a 784 long vector\n",
    "#            images = images.view(images.shape[0], -1)\n",
    "    \n",
    "            # TODO: Training pass\n",
    "#            optimizer.zero_grad()\n",
    "         \n",
    "#            output = model(images)\n",
    "#            loss = criterion(output, labels)\n",
    "       \n",
    "#            loss.backward()\n",
    "#            optimizer.step()\n",
    "        \n",
    "#            running_loss += loss.item()\n",
    "#        else:\n",
    "#            print(\"Training loss:\", running_loss/len(trainloader))\n",
    "#            print(loss)\n",
    "\n",
    "#    print(\"==>\",device, time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: cuda\n",
      "epoch 0\n",
      "Training loss: 1.8353474710795925\n",
      "tensor(1.0960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 1\n",
      "Training loss: 0.7973223469976677\n",
      "tensor(0.5507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 2\n",
      "Training loss: 0.5152868412609802\n",
      "tensor(0.2985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 3\n",
      "Training loss: 0.42452582486593393\n",
      "tensor(0.3563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 4\n",
      "Training loss: 0.3811920700646413\n",
      "tensor(0.4300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 5\n",
      "Training loss: 0.354966407971405\n",
      "tensor(0.2881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 6\n",
      "Training loss: 0.3359381866607585\n",
      "tensor(0.2992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 7\n",
      "Training loss: 0.3210939739320451\n",
      "tensor(0.2612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 8\n",
      "Training loss: 0.30830734365307955\n",
      "tensor(0.5859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "epoch 9\n",
      "Training loss: 0.2974940584793782\n",
      "tensor(0.7527, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using:\",device)\n",
    "\n",
    "model.to(device)\n",
    "    \n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    print(\"epoch\",e)\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #images = images.to(device)\n",
    "        #labels = labels.to(device)\n",
    "        images, labels = images.to(device), labels.to(device)        \n",
    "            \n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    " \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Training loss:\", running_loss/len(trainloader))\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "images, labels = images.to(\"cpu\"), labels.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.state_dict().keys()\n",
    "torch.save(model.state_dict(), 'checkpoint-mnist-10.pth')\n",
    "#state_dict = torch.load('checkpoint1-dropout.pth')\n",
    "#print(state_dict.keys())\n",
    "#model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# flatten structure above\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "# get back softmax without log\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reference:</p>\n",
    "    \n",
    "<a href='https://www.udacity.com/course/deep-learning-pytorch--ud188'>Udacity: Intro to deep learning with PyTorch</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
